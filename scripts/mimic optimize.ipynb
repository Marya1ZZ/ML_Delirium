{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ff5177-3d62-4092-a5b6-5d95c55f3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMIC IV Nth attempt \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Step 1: Define Data Path for Local Execution\n",
    "# Modify this path to the location of your MIMIC-IV data on your hard drive\n",
    "data_path = \"D:/mimic-iv-3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc3eb40-06ee-4a96-8e92-eccbca4073d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage: 30.4%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import psutil\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Step 1: Define Data Path for Local Execution\n",
    "data_path = \"D:/mimic-iv-3.1\"\n",
    "\n",
    "# Step 2: Check memory usage before loading data\n",
    "def check_memory():\n",
    "    print(f\"Memory Usage: {psutil.virtual_memory().percent}%\")\n",
    "\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f245c271-66e1-48e5-aea0-2f7ab81ff110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load MIMIC-IV Tables with optimized memory handling\n",
    "# Load small tables directly\n",
    "admissions = pd.read_csv(os.path.join(data_path, \"hosp/admissions.csv.gz\"), \n",
    "                          usecols=[\"subject_id\", \"hadm_id\", \"admittime\", \"dischtime\"], \n",
    "                          low_memory=False)\n",
    "\n",
    "patients = pd.read_csv(os.path.join(data_path, \"hosp/patients.csv.gz\"), \n",
    "                        usecols=[\"subject_id\", \"gender\", \"anchor_age\", \"anchor_year\", \"dod\"], \n",
    "                        low_memory=False)\n",
    "\n",
    "icustays = pd.read_csv(os.path.join(data_path, \"icu/icustays.csv.gz\"), \n",
    "                        usecols=[\"subject_id\", \"hadm_id\", \"stay_id\", \"intime\", \"outtime\"], \n",
    "                        low_memory=False)\n",
    "\n",
    "diagnoses = pd.read_csv(os.path.join(data_path, \"hosp/diagnoses_icd.csv.gz\"), \n",
    "                         usecols=[\"subject_id\", \"hadm_id\", \"icd_code\"], \n",
    "                         low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7ecfa8-1266-45ed-9725-81f26dc09dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load large tables in chunks\n",
    "chunk_size = 250000  # Adjust based on system memory\n",
    "\n",
    "prescriptions_iter = pd.read_csv(os.path.join(data_path, \"hosp/prescriptions.csv.gz\"), \n",
    "                                  usecols=[\"subject_id\", \"hadm_id\", \"drug\"], \n",
    "                                  dtype=str, \n",
    "                                  low_memory=False, \n",
    "                                  chunksize=chunk_size)\n",
    "prescriptions = pd.concat(prescriptions_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6983ad0d-07db-4673-966f-70b6b3b6fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250000  # Adjust based on system memory\n",
    "lab_events_iter = pd.read_csv(os.path.join(data_path, \"hosp/labevents.csv.gz\"), \n",
    "                               usecols=[\"subject_id\", \"hadm_id\", \"itemid\", \"valuenum\"], \n",
    "                               low_memory=False, \n",
    "                               chunksize=chunk_size)\n",
    "lab_events = pd.concat(lab_events_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47a11287-f141-4e2a-869e-6e8f0fc3da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250000  # Adjust based on system memory\n",
    "chartevents_iter = pd.read_csv(os.path.join(data_path, \"icu/chartevents.csv.gz\"), \n",
    "                                usecols=[\"subject_id\", \"hadm_id\", \"itemid\", \"valuenum\"], \n",
    "                                low_memory=False, \n",
    "                                chunksize=chunk_size)\n",
    "chartevents = pd.concat(chartevents_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b8204d9-e13c-4938-9882-e606b196d6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage: 59.8%\n",
      "âœ… Processed dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Check memory usage after loading data\n",
    "check_memory()\n",
    "\n",
    "# Step 5: Save Processed Data for ML Modeling\n",
    "output_path = \"D:/MIMIC-IV-Data-Pipeline/processed_data\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "admissions.to_csv(os.path.join(output_path, \"admissions_processed.csv.gz\"), index=False, compression='gzip')\n",
    "patients.to_csv(os.path.join(output_path, \"patients_processed.csv.gz\"), index=False, compression='gzip')\n",
    "icustays.to_csv(os.path.join(output_path, \"icustays_processed.csv.gz\"), index=False, compression='gzip')\n",
    "diagnoses.to_csv(os.path.join(output_path, \"diagnoses_processed.csv.gz\"), index=False, compression='gzip')\n",
    "prescriptions.to_csv(os.path.join(output_path, \"prescriptions_processed.csv.gz\"), index=False, compression='gzip')\n",
    "lab_events.to_csv(os.path.join(output_path, \"lab_events_processed.csv.gz\"), index=False, compression='gzip')\n",
    "chartevents.to_csv(os.path.join(output_path, \"chartevents_processed.csv.gz\"), index=False, compression='gzip')\n",
    "\n",
    "print(\"âœ… Processed dataset saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04ee9349-5943-461e-bf61-30931b71bc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage: 74.6%\n"
     ]
    }
   ],
   "source": [
    "# Load item labels to be merged later\n",
    "d_items = pd.read_csv(os.path.join(data_path, \"icu/d_items.csv.gz\"), usecols=[\"itemid\", \"label\"], low_memory=False)\n",
    "d_labitems = pd.read_csv(os.path.join(data_path, \"hosp/d_labitems.csv.gz\"), usecols=[\"itemid\", \"label\"], low_memory=False)\n",
    "d_procedures = pd.read_csv(os.path.join(data_path, \"hosp/d_icd_procedures.csv.gz\"), usecols=[\"icd_code\", \"long_title\"], low_memory=False)\n",
    "\n",
    "# Step 4a: Check memory usage after loading data\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c14beb89-9533-4872-adda-146adf41572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5a: Merge Data for Delirium Prediction\n",
    "core_data = pd.merge(admissions, patients, on=\"subject_id\", how=\"inner\")\n",
    "core_data = pd.merge(core_data, icustays, on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
    "core_data = pd.merge(core_data, diagnoses, on=[\"subject_id\", \"hadm_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "716799aa-92cb-4880-b815-98f8a0d4ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Delirium Cases Using ICD Codes\n",
    "delirium_icd_codes = ['F05', '293.0', '293.1']  # ICD-10 & ICD-9 codes\n",
    "core_data[\"delirium\"] = core_data[\"icd_code\"].isin(delirium_icd_codes).astype(int)\n",
    "\n",
    "# Comorbidity Identification\n",
    "comorbidity_count = diagnoses.groupby([\"subject_id\", \"hadm_id\"])['icd_code'].nunique().reset_index()\n",
    "comorbidity_count.rename(columns={'icd_code': 'num_comorbidities'}, inplace=True)\n",
    "core_data = pd.merge(core_data, comorbidity_count, on=[\"subject_id\", \"hadm_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e606d216-da6e-4ffc-8a19-a25a025cab5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Delirium prediction dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Merge ICU procedures\n",
    "diagnoses_labeled = pd.merge(diagnoses, d_procedures, on=\"icd_code\", how=\"left\")\n",
    "primary_procedure = diagnoses_labeled.groupby([\"subject_id\", \"hadm_id\"])['long_title'].first().reset_index()\n",
    "primary_procedure.rename(columns={'long_title': 'primary_procedure'}, inplace=True)\n",
    "core_data = pd.merge(core_data, primary_procedure, on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
    "\n",
    "# Merge lab events with labels\n",
    "lab_events_labeled = pd.merge(lab_events, d_labitems, on=\"itemid\", how=\"left\")\n",
    "lab_events_median = lab_events_labeled.groupby([\"subject_id\", \"hadm_id\", \"label\"])[\"valuenum\"].median().reset_index()\n",
    "lab_events_pivot = lab_events_median.pivot(index=[\"subject_id\", \"hadm_id\"], columns=\"label\", values=\"valuenum\").reset_index()\n",
    "core_data = pd.merge(core_data, lab_events_pivot, on=[\"subject_id\", \"hadm_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "740dc3ed-243d-4ccb-b9a1-07b4955dd832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Delirium prediction dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6: Save Processed Data for ML Modeling\n",
    "output_path = \"D:/MIMIC-IV-Data-Pipeline/processed_data\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "core_data.to_csv(os.path.join(output_path, \"delirium_prediction_data.csv.gz\"), index=False, compression='gzip')\n",
    "\n",
    "print(\"âœ… Delirium prediction dataset saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac622c2-d383-4633-88f1-5755b26b8516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_id           int64\n",
      "hadm_id              int64\n",
      "admittime           object\n",
      "dischtime           object\n",
      "gender              object\n",
      "                    ...   \n",
      "pH                 float64\n",
      "pO2                float64\n",
      "proBNP, Pleural    float64\n",
      "tacroFK            float64\n",
      "wbcp               float64\n",
      "Length: 728, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"D:/MIMIC-IV-Data-Pipeline/processed_data/delirium_prediction_data.csv.gz\"\n",
    "\n",
    "df_sample = pd.read_csv(file_path, compression=\"gzip\", nrows=5)  # Load first 5 rows to inspect\n",
    "print(df_sample.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b1b19-c747-4e3e-8bd3-749a0cb9431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Exists: True\n"
     ]
    }
   ],
   "source": [
    "#EDA redone \n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"D:/MIMIC-IV-Data-Pipeline/processed_data/delirium_prediction_data.csv.gz\"\n",
    "print(\"File Exists:\", os.path.exists(file_path))\n",
    "\n",
    "# Load dataset correctly\n",
    "df = pd.read_csv(file_path, compression=\"gzip\")\n",
    "\n",
    "print(\"âœ… File loaded successfully! Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88d34432-59e3-42a3-9632-3ed68eb79a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\truly\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\truly\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\truly\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\truly\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\truly\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\truly\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\truly\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\truly\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\truly\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\truly\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\truly\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\truly\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\truly\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\truly\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\truly\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "#Install necessary packages (if not already installed)\n",
    "!pip install pandas matplotlib seaborn\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb868d8f-709e-4132-8e20-ee2fe61fc885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id            admittime            dischtime gender  \\\n",
      "0    10000032  22595853  2180-05-06 22:23:00  2180-05-07 17:15:00      F   \n",
      "1    10000032  22595853  2180-05-06 22:23:00  2180-05-07 17:15:00      F   \n",
      "2    10000032  22595853  2180-05-06 22:23:00  2180-05-07 17:15:00      F   \n",
      "3    10000032  22595853  2180-05-06 22:23:00  2180-05-07 17:15:00      F   \n",
      "4    10000032  22595853  2180-05-06 22:23:00  2180-05-07 17:15:00      F   \n",
      "\n",
      "   anchor_age  anchor_year         dod  stay_id  intime  ...  \\\n",
      "0          52         2180  2180-09-09      NaN     NaN  ...   \n",
      "1          52         2180  2180-09-09      NaN     NaN  ...   \n",
      "2          52         2180  2180-09-09      NaN     NaN  ...   \n",
      "3          52         2180  2180-09-09      NaN     NaN  ...   \n",
      "4          52         2180  2180-09-09      NaN     NaN  ...   \n",
      "\n",
      "   dRVVT - Confirmation  dRVVT - Normalized Ratio  dRVVT - Screen  eAG pCO2  \\\n",
      "0                   NaN                       NaN             NaN  NaN  NaN   \n",
      "1                   NaN                       NaN             NaN  NaN  NaN   \n",
      "2                   NaN                       NaN             NaN  NaN  NaN   \n",
      "3                   NaN                       NaN             NaN  NaN  NaN   \n",
      "4                   NaN                       NaN             NaN  NaN  NaN   \n",
      "\n",
      "    pH  pO2  proBNP, Pleural  tacroFK  wbcp  \n",
      "0  6.0  NaN              NaN      NaN   NaN  \n",
      "1  6.0  NaN              NaN      NaN   NaN  \n",
      "2  6.0  NaN              NaN      NaN   NaN  \n",
      "3  6.0  NaN              NaN      NaN   NaN  \n",
      "4  6.0  NaN              NaN      NaN   NaN  \n",
      "\n",
      "[5 rows x 728 columns]\n"
     ]
    }
   ],
   "source": [
    "df_sample = pd.read_csv(file_path, compression=\"gzip\", nrows=5)\n",
    "print(df_sample.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87e23c73-b7cc-4524-9050-29a94a745eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\truly\\AppData\\Local\\Temp\\ipykernel_12340\\998735594.py:5: DtypeWarning: Columns (7,9,10,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 35.2 GiB for an array with shape (715, 6599888) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/MIMIC-IV-Data-Pipeline/processed_data/delirium_prediction_data.csv.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[1;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m   1969\u001b[0m         new_col_dict,\n\u001b[0;32m   1970\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   1971\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   1972\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write(),\n\u001b[0;32m   1973\u001b[0m     )\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    153\u001b[0m         arrays, axes, consolidate\u001b[38;5;241m=\u001b[39mconsolidate, refs\u001b[38;5;241m=\u001b[39mrefs\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2144\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2142\u001b[0m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2144\u001b[0m     mgr\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m   2145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2267\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2269\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2270\u001b[0m         \u001b[38;5;28mlist\u001b[39m(group_blocks), dtype\u001b[38;5;241m=\u001b[39mdtype, can_consolidate\u001b[38;5;241m=\u001b[39m_can_consolidate\n\u001b[0;32m   2271\u001b[0m     )\n\u001b[0;32m   2272\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2301\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2298\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2300\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2301\u001b[0m new_values \u001b[38;5;241m=\u001b[39m new_values[argsort]\n\u001b[0;32m   2302\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2304\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 35.2 GiB for an array with shape (715, 6599888) and data type float64"
     ]
    }
   ],
   "source": [
    "# Define the dataset path  \n",
    "file_path = \"D:/MIMIC-IV-Data-Pipeline/processed_data/delirium_prediction_data.csv.gz\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)  #gives memory error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c4fb3-f7bb-45b6-95bd-0fc630dd5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    file_path, compression=\"gzip\", usecols=selected_columns, low_memory=False,\n",
    "    dtype={\"delirium\": \"int8\", \"anchor_age\": \"int16\", \"num_comorbidities\": \"int8\"}\n",
    ")\n",
    "chunk_size = 20000  # Adjust based on system capacity\n",
    "df_chunks = pd.read_csv(file_path, compression=\"gzip\", usecols=selected_columns, chunksize=chunk_size)\n",
    "\n",
    "df = pd.concat(df_chunks)  # Combine chunks after processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "292543c0-29a0-4225-b8b0-efef9895be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'hadm_id', 'admittime', 'dischtime', 'gender',\n",
      "       'anchor_age', 'anchor_year', 'dod', 'stay_id', 'intime',\n",
      "       ...\n",
      "       'dRVVT - Confirmation', 'dRVVT - Normalized Ratio', 'dRVVT - Screen',\n",
      "       'eAG', 'pCO2', 'pH', 'pO2', 'proBNP, Pleural', 'tacroFK', 'wbcp'],\n",
      "      dtype='object', length=728)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"D:/MIMIC-IV-Data-Pipeline/processed_data/delirium_prediction_data.csv.gz\"\n",
    "\n",
    "df_sample = pd.read_csv(file_path, compression=\"gzip\", nrows=5)  # Load only first 5 rows\n",
    "print(df_sample.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00265a39-8276-43ca-9be7-e429adb4f6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset Loaded Successfully!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ðŸ”¹ Basic Data Overview\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Dataset Loaded Successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMissing Values:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# ðŸ”¹ Basic Data Overview\n",
    "print(\"âœ… Dataset Loaded Successfully!\")\n",
    "print(f\"Shape of dataset: {df.shape}\")\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nUnique Values Per Column:\")\n",
    "print(df.nunique())\n",
    "\n",
    "# ðŸ”¹ Summary Statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# ðŸ”¹ Class Distribution (Delirium vs. Non-Delirium)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"delirium\", data=df, palette=\"coolwarm\")\n",
    "plt.title(\"Distribution of Delirium Cases\")\n",
    "plt.xlabel(\"Delirium (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee2017-3570-4996-a317-a61a621017da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ Histograms for Numeric Features\n",
    "df.hist(figsize=(12, 10), bins=30)\n",
    "plt.suptitle(\"Feature Distributions\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# ðŸ”¹ Boxplots for Key Clinical Features\n",
    "clinical_features = [\"anchor_age\", \"num_comorbidities\"]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, feature in enumerate(clinical_features, 1):\n",
    "    plt.subplot(1, len(clinical_features), i)\n",
    "    sns.boxplot(x=\"delirium\", y=feature, data=df)\n",
    "    plt.title(f\"{feature} vs Delirium\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ðŸ”¹ Feature Correlation Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… EDA Completed Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6160a-9f81-487c-b7e5-c3a8493ac75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS CELL YET \n",
    "#Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Define dataset path (Update if necessary)\n",
    "file_path = \"D:/MIMIC-IV-Data-Pipeline/processed_data/delirium_prediction_data.csv.gz\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"D:/MIMIC-IV-Data-Pipeline/EDA_Results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# âœ… Save Basic Data Overview\n",
    "eda_summary = {\n",
    "    \"Shape\": df.shape,\n",
    "    \"Missing Values\": df.isnull().sum(),\n",
    "    \"Data Types\": df.dtypes,\n",
    "    \"Unique Values\": df.nunique()\n",
    "}\n",
    "eda_summary_df = pd.DataFrame(eda_summary)\n",
    "eda_summary_df.to_csv(os.path.join(output_dir, \"eda_summary.csv\"))\n",
    "\n",
    "# âœ… Save Summary Statistics\n",
    "df.describe().to_csv(os.path.join(output_dir, \"summary_statistics.csv\"))\n",
    "\n",
    "# âœ… Save Class Distribution\n",
    "class_distribution = df[\"delirium\"].value_counts(normalize=True)\n",
    "class_distribution.to_csv(os.path.join(output_dir, \"class_distribution.csv\"))\n",
    "\n",
    "# âœ… Save Feature Correlation Matrix\n",
    "correlation_matrix = df.corr()\n",
    "correlation_matrix.to_csv(os.path.join(output_dir, \"feature_correlations.csv\"))\n",
    "\n",
    "# ðŸ”¹ Save Plots\n",
    "# Class Distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"delirium\", data=df, palette=\"coolwarm\")\n",
    "plt.title(\"Distribution of Delirium Cases\")\n",
    "plt.xlabel(\"Delirium (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig(os.path.join(output_dir, \"class_distribution.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Histograms for Numeric Features\n",
    "df.hist(figsize=(12, 10), bins=30)\n",
    "plt.suptitle(\"Feature Distributions\", fontsize=16)\n",
    "plt.savefig(os.path.join(output_dir, \"feature_histograms.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Boxplots for Key Clinical Features\n",
    "clinical_features = [\"anchor_age\", \"num_comorbidities\"]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, feature in enumerate(clinical_features, 1):\n",
    "    plt.subplot(1, len(clinical_features), i)\n",
    "    sns.boxplot(x=\"delirium\", y=feature, data=df)\n",
    "    plt.title(f\"{feature} vs Delirium\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"boxplots.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.savefig(os.path.join(output_dir, \"correlation_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"âœ… EDA completed! Results saved in: {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
